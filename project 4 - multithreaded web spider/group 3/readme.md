#Description
## MultiThreaded web spider
A web sipder that simultaneously crawls five web ursl. 
## Prerequisite
python environment, prefereably python 207
## Brief Description
defines the part of the page you are interested in crawling   
   example, links are extracted by this crawler   
   also define how deep the crawler should go. i.e the dept  
   
For each of the five (5) links defined   
    crawl the defined web server on a new thread.
    parse the page and extracted the links if within the dept defined  
    display the extracted links 
## Conclusion
  successfully and simultaneously crawl links from different web pages.
  
  the multithreadedspider2.py is the file on the description.
